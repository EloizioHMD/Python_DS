{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forests(Kaggle).ipynb",
      "provenance": [],
      "mount_file_id": "15XiJ36IT71jC6ZGAJ3_SG2v3q0jr7rr_",
      "authorship_tag": "ABX9TyMb1dNVQ3jHXsoRcKx6qwLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EloizioHMD/Python_DS/blob/main/Random_Forests(Kaggle).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forests (Competição de preços de moradia para usuários do Kaggle Learn)\n",
        "\n",
        "![](https://storage.googleapis.com/kaggle-competitions/kaggle/5407/media/housesbanner.png)\n",
        "\n",
        "Notebook por [Eloízio Dantas](https://www.linkedin.com/in/eloiziohmdantas/).\n",
        "Atividade proposta [Kaggle](https://www.kaggle.com/) no curso [Intro to Machine Learning](https://www.kaggle.com/learn/intro-to-machine-learning). "
      ],
      "metadata": {
        "id": "j79bDJ0bvqOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse notebook é uma continuação do problema tratado no [Decision Tree Regressor - Preço casa Kaggle](https://github.com/EloizioHMD/Python_DS/blob/main/Decision_Tree_Regressor(Kaggle).ipynb). Então para mais detalhes da uma conferida lá."
      ],
      "metadata": {
        "id": "Ra0gWCutwHER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As árvores de decisão deixam você com uma decisão difícil. Uma árvore profunda com muitas folhas se ajustará demais porque cada previsão vem de dados históricos de apenas algumas casas em sua folha. Mas uma árvore rasa com poucas folhas terá um desempenho ruim porque não consegue capturar tantas distinções nos dados brutos.\n",
        "\n",
        "Mesmo as técnicas de modelagem mais sofisticadas de hoje enfrentam essa tensão entre underfitting e overfitting. Mas, muitos modelos têm ideias inteligentes que podem levar a um melhor desempenho. É o caso do modelo que vamos implementar a seguir: Random Forests."
      ],
      "metadata": {
        "id": "aA5PpmDbxZfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando os Dados"
      ],
      "metadata": {
        "id": "5QFftpV3x2xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui vamos otimizar e apenas carregar os dados necessários para em seguida aplicar o modelo."
      ],
      "metadata": {
        "id": "U3kabKM7yNKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "tAcXntdIwGY8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando arquivos para Pandas Dataframe\n",
        "iowa_data = pd.read_csv('/content/drive/MyDrive/Awari/data_science/iowa_train.csv')\n",
        "\n",
        "# Criando o alvo(y)\n",
        "y = iowa_data.SalePrice\n",
        "# Criando os previsores(X)\n",
        "recursos = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'GrLivArea', 'GarageArea']\n",
        "X = iowa_data[recursos]\n",
        "\n",
        "# Dividido em dados de validação(val) e treinamento(train)\n",
        "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
      ],
      "metadata": {
        "id": "JRhgQn74zCrU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usando o Random Forest"
      ],
      "metadata": {
        "id": "gug9yPHl1FuD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma Random Forest é um meta estimador que ajusta um número de árvores de decisão de classificação em várias subamostras do conjunto de dados e usa a média para melhorar a precisão preditiva e controlar o ajuste excessivo. O tamanho da subamostra é controlado com o parâmetro max_samples se bootstrap=True (padrão), caso contrário, todo o conjunto de dados é usado para construir cada árvore.\n",
        "\n",
        "Mais informação na documentaçãok do [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)."
      ],
      "metadata": {
        "id": "oLh7Kknw4XVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Define the model. Set random_state to 1\n",
        "modelo_RF = RandomForestRegressor()\n",
        "# Ajuste do modelo\n",
        "modelo_RF.fit(train_X, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o08ijzM61RDG",
        "outputId": "60ff5762-e81c-4926-8a86-65e9855b1c1c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando o erro absoluto médio (MAE) do modelo nos dados de validação\n",
        "val_RF_prev = modelo_RF.predict(val_X)\n",
        "val_RF_mae = mean_absolute_error(val_RF_prev, val_y)"
      ],
      "metadata": {
        "id": "MRcrP4nk14S2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados"
      ],
      "metadata": {
        "id": "4KDO7Rq82p0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Previsão da validação:', modelo_RF.predict(val_X.head()))\n",
        "print('Valores reais da validação:', val_y.head().tolist())\n",
        "print('MAE da validação:', val_RF_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GvLnVG02sNN",
        "outputId": "bb960cb8-afc3-4232-d6d8-36122e918919"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previsão da validação: [211716.6  177614.53 120367.    85918.   151958.59]\n",
            "Valores reais da validação: [231500, 179500, 122000, 84500, 142000]\n",
            "MAE da validação: 21109.473103065884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provavelmente há espaço para melhoria. Existem parâmetros que permitem alterar o desempenho da Random Forest da mesma forma que alteramos a profundidade máxima da árvore de decisão única.\n",
        "\n",
        "Note que sem ajustes ele se saiu melhor que a Decision Tree Regressor. Uma das melhores características dos modelos Random Forest é que eles geralmente funcionam razoavelmente mesmo sem ajustes."
      ],
      "metadata": {
        "id": "xebga1Jg5RD6"
      }
    }
  ]
}